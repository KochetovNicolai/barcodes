{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for Natural Language Processing\n",
    "\n",
    "\n",
    " * Simple text representations, bag of words\n",
    " * Word embedding and... not just another word2vec this time\n",
    " * rnn for text\n",
    " * Aggregating several data sources \"the hard way\"\n",
    " * Solving ~somewhat~ real ML problem with ~almost~ end-to-end deep learning\n",
    " \n",
    "\n",
    "Special thanks to Irina Golzmann for help with technical part, task prepared by Александр Панин, jheuristic@yandex-team.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "You will require nltk v3.2 to solve this assignment\n",
    "\n",
    "__It is really important that the version is 3.2, otherwize russian tokenizer might not work__\n",
    "\n",
    "Install/update\n",
    "* `sudo pip install --upgrade nltk==3.2`\n",
    "* If you don't remember when was the last pip upgrade, `sudo pip install --upgrade pip`\n",
    "\n",
    "If for some reason you can't or won't switch to nltk v3.2, just make sure that russian words are tokenized properly with RegeExpTokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For students with low-RAM machines\n",
    " * This assignment can be accomplished with even the low-tier hardware (<= 4Gb RAM) \n",
    " * If that is the case, turn flag \"low_RAM_mode\" below to True\n",
    " * If you have around 8GB memory, it is unlikely that you will feel constrained by memory.\n",
    " * In case you are using a PC from last millenia, consider setting very_low_RAM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = True\n",
    "very_low_RAM = False  #If you have <3GB RAM, set BOTH to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Ex-kaggle-competition on prohibited content detection\n",
    "\n",
    "There goes the description - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Download\n",
    "High-RAM mode,\n",
    " * Download avito_train.tsv from competition data files\n",
    "Low-RAM-mode,\n",
    " * Download downsampled dataset from here\n",
    "     * archive https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * raw https://yadi.sk/d/I1v7mZ6Sqw2WK (in case you feel masochistic)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What's inside\n",
    "Different kinds of features:\n",
    "* 2 text fields - title and description\n",
    "* Special features - price, number of e-mails, phones, etc\n",
    "* Category and subcategory - unsurprisingly, categorical features\n",
    "* Attributes - more factors\n",
    "\n",
    "Only 1 binary target whether or not such advertisement contains prohibited materials\n",
    "* criminal, misleading, human reproduction-related, etc\n",
    "* diving into the data may result in prolonged sleep disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # a lot of ram\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #aroung 4GB ram\n",
    "    df = pd.read_csv(\"avito_train_1kk.tsv\",sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204949, 13) 0.228222107326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000299</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Костюм Didriksons Boardman, размер 100, краги,...</td>\n",
       "      <td>Костюм Didriksons Boardman, в отличном состоян...</td>\n",
       "      <td>{\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000309</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>1-к квартира, 44 м², 9/20 эт.</td>\n",
       "      <td>В кирпичном пан.-м доме, продается одноком.-ая...</td>\n",
       "      <td>{\"Тип объявления\":\"Продам\", \"Количество комнат...</td>\n",
       "      <td>2642020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000317</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Поездки на таможню, печать в паспорте</td>\n",
       "      <td>Поездки на таможню гражданам СНГ для пересечен...</td>\n",
       "      <td>{\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid      category                subcategory  \\\n",
       "0  10000010     Транспорт      Автомобили с пробегом   \n",
       "1  10000094   Личные вещи  Одежда, обувь, аксессуары   \n",
       "2  10000299   Личные вещи     Детская одежда и обувь   \n",
       "3  10000309  Недвижимость                   Квартиры   \n",
       "4  10000317        Услуги          Предложения услуг   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Toyota Sera, 1991   \n",
       "1                                   Костюм Steilmann   \n",
       "2  Костюм Didriksons Boardman, размер 100, краги,...   \n",
       "3                      1-к квартира, 44 м², 9/20 эт.   \n",
       "4              Поездки на таможню, печать в паспорте   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "2  Костюм Didriksons Boardman, в отличном состоян...   \n",
       "3  В кирпичном пан.-м доме, продается одноком.-ая...   \n",
       "4  Поездки на таможню гражданам СНГ для пересечен...   \n",
       "\n",
       "                                               attrs    price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...   150000        NaN   \n",
       "1  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...     1500        NaN   \n",
       "2  {\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...     3000        NaN   \n",
       "3  {\"Тип объявления\":\"Продам\", \"Количество комнат...  2642020        NaN   \n",
       "4  {\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...     1500          0   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           0           0         0         0.41  \n",
       "2           0           0           0         0         5.49  \n",
       "3           0           1           0         0        22.47  \n",
       "4           1           0           0         0         1.43  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.228222107326\n",
      "Count: 1204949\n"
     ]
    }
   ],
   "source": [
    "print \"Blocked ratio\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance-out the classes\n",
    "* Vast majority of data samples are non-prohibited\n",
    " * 250k banned out of 4kk\n",
    " * Let's just downsample random 250k legal samples to make further steps less computationally demanding\n",
    " * If you aim for high Kaggle score, consider a smarter approach to that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((274996,), (929953,))\n",
      "[1015855  314361  285157 ...,  653410   30692  571578]\n",
      "((549992,), array([     4,      5,      6, ..., 653410,  30692, 571578]))\n",
      "Blocked ratio: 0.5\n",
      "Count: 549992\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "blocked_indexes = np.array(df[df['is_blocked'] == 1].index.tolist())\n",
    "other_indexes = np.array(df[df['is_blocked'] != 1].index.tolist())\n",
    "print(blocked_indexes.shape, other_indexes.shape)\n",
    "perm = np.random.permutation(len(other_indexes))[:len(blocked_indexes)]\n",
    "other_indexes = other_indexes[perm]\n",
    "print(other_indexes)\n",
    "indexes = np.concatenate((blocked_indexes, other_indexes))\n",
    "print(indexes.shape, indexes)\n",
    "\n",
    "#< downsample data so that both classes have approximately equal ratios>\n",
    "\n",
    "#df = <downsampled dataset>\n",
    "\n",
    "df = df.iloc[indexes]\n",
    "\n",
    "print \"Blocked ratio:\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'very_low_ram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7cd356d2aa3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#In case your RAM-o-meter is in the red\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mvery_low_ram\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'very_low_ram' is not defined"
     ]
    }
   ],
   "source": [
    "#In case your RAM-o-meter is in the red\n",
    "if very_low_ram:\n",
    "    data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tokenizing\n",
    "\n",
    "First, we create a dictionary of all existing words.\n",
    "Assign each word a number - it's Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare tokens\n",
    "\n",
    "We are unlikely to make use of words that are only seen a few times throughout the corpora.\n",
    "\n",
    "Again, if you want to beat Kaggle competition metrics, consider doing something better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDUlSt/8PD2e2La3I6PsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5be7bfe90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_=plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "\n",
    "min_count = 10\n",
    "tokens = np.array([token for token in token_counts.keys() if token_counts[token] >= 10])\n",
    "#<tokens from token_counts keys that had at least min_count occurences throughout the dataset>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 87998\n"
     ]
    }
   ],
   "source": [
    "print \"# Tokens:\",len(token_to_id)\n",
    "if len(token_to_id) < 30000:\n",
    "    print \"Alarm! It seems like there are too few tokens. Make sure you updated NLTK and applied correct thresholds -- unless you now what you're doing, ofc\"\n",
    "if len(token_to_id) > 1000000:\n",
    "    print \"Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs\n",
    "Set a maximum length for titles and descriptions.\n",
    " * If string is longer that that limit - crop it, if less - pad with zeros.\n",
    " * Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    " * Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token,0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data format examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (549992, 15)\n",
      "Поездки на таможню, печать в паспорте -> [43272 14675 55381 82142 80216 17337     0     0     0     0] ...\n",
      "Рефлекторно-урогинекологический массаж -> [ 8357     0 30474     0     0     0     0     0     0     0] ...\n",
      "Возьму суду под200 т. р -> [28846 23379     0  3644 33955     0     0     0     0     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ As you can see, our preprocessing is somewhat crude. Let us see if that is enough for our network __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-sequences\n",
    "\n",
    "\n",
    "Some data features are not text samples. E.g. price, # urls, category, etc\n",
    "\n",
    "They require a separate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values\n",
    "\n",
    "#categories = [A list of dictionaries {\"category\":category_name, \"subcategory\":subcategory_name} for each data sample]\n",
    "categories = [{\"category\":category_name, \"subcategory\":subcategory_name} for category_name, subcategory_name in data_cat_subcat]\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>price</th>\n",
       "      <th>category=Бытовая электроника</th>\n",
       "      <th>category=Для бизнеса</th>\n",
       "      <th>category=Для дома и дачи</th>\n",
       "      <th>category=Животные</th>\n",
       "      <th>category=Личные вещи</th>\n",
       "      <th>category=Недвижимость</th>\n",
       "      <th>...</th>\n",
       "      <th>subcategory=Резюме</th>\n",
       "      <th>subcategory=Ремонт и строительство</th>\n",
       "      <th>subcategory=Собаки</th>\n",
       "      <th>subcategory=Спорт и отдых</th>\n",
       "      <th>subcategory=Телефоны</th>\n",
       "      <th>subcategory=Товары для детей и игрушки</th>\n",
       "      <th>subcategory=Товары для животных</th>\n",
       "      <th>subcategory=Товары для компьютера</th>\n",
       "      <th>subcategory=Фототехника</th>\n",
       "      <th>subcategory=Часы и украшения</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.800000e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   phones_cnt  emails_cnt  urls_cnt         price  \\\n",
       "0    0.000000         0.0         0  1.500000e-06   \n",
       "1    0.000000         0.0         0  1.000000e-06   \n",
       "2    0.000000         0.0         0  0.000000e+00   \n",
       "3    0.003125         0.2         0  0.000000e+00   \n",
       "4    0.000000         0.0         0  1.800000e-08   \n",
       "\n",
       "   category=Бытовая электроника  category=Для бизнеса  \\\n",
       "0                             0                     0   \n",
       "1                             0                     0   \n",
       "2                             0                     0   \n",
       "3                             0                     0   \n",
       "4                             0                     0   \n",
       "\n",
       "   category=Для дома и дачи  category=Животные  category=Личные вещи  \\\n",
       "0                         0                  0                     0   \n",
       "1                         0                  0                     0   \n",
       "2                         0                  0                     0   \n",
       "3                         0                  0                     0   \n",
       "4                         0                  0                     1   \n",
       "\n",
       "   category=Недвижимость              ...               subcategory=Резюме  \\\n",
       "0                      0              ...                                0   \n",
       "1                      0              ...                                0   \n",
       "2                      0              ...                                0   \n",
       "3                      0              ...                                0   \n",
       "4                      0              ...                                0   \n",
       "\n",
       "   subcategory=Ремонт и строительство  subcategory=Собаки  \\\n",
       "0                                   0                   0   \n",
       "1                                   0                   0   \n",
       "2                                   0                   0   \n",
       "3                                   0                   0   \n",
       "4                                   0                   0   \n",
       "\n",
       "   subcategory=Спорт и отдых  subcategory=Телефоны  \\\n",
       "0                          0                     0   \n",
       "1                          0                     0   \n",
       "2                          0                     0   \n",
       "3                          0                     0   \n",
       "4                          0                     0   \n",
       "\n",
       "   subcategory=Товары для детей и игрушки  subcategory=Товары для животных  \\\n",
       "0                                       0                                0   \n",
       "1                                       0                                0   \n",
       "2                                       0                                0   \n",
       "3                                       0                                0   \n",
       "4                                       0                                0   \n",
       "\n",
       "   subcategory=Товары для компьютера  subcategory=Фототехника  \\\n",
       "0                                  0                        0   \n",
       "1                                  0                        0   \n",
       "2                                  0                        0   \n",
       "3                                  0                        0   \n",
       "4                                  0                        0   \n",
       "\n",
       "   subcategory=Часы и украшения  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_text['price'] /= max(df_non_text['price'])\n",
    "df_non_text['phones_cnt'] /= max(df_non_text['phones_cnt'])\n",
    "df_non_text['emails_cnt'] /= max(df_non_text['emails_cnt'])\n",
    "df_non_text['urls_cnt'] /= max(df_non_text['urls_cnt'])\n",
    "df_non_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#Non-sequences\n",
    "df_non_text = df_non_text.astype('float32').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43272 14675 55381 ...,     0     0     0]\n",
      " [54053 13437 81785 ...,     0     0     0]\n",
      " [28846 23379 74529 ...,     0     0     0]\n",
      " ..., \n",
      " [27621 49443 80216 ...,     0     0     0]\n",
      " [24337 37300 54350 ...,     0     0     0]\n",
      " [11571 39659 87373 ...,     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print desc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(df_non_text).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into training and test set.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#Difficulty selector:\n",
    "#Easy: split randomly\n",
    "#Medium: select test set items that have item_ids strictly above that of training set\n",
    "#Hard: do whatever you want, but score yourself using kaggle private leaderboard\n",
    "\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = \\\n",
    "    train_test_split(title_tokens, desc_tokens, df_non_text, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412494, 15)\n",
      "(137498, 15)\n"
     ]
    }
   ],
   "source": [
    "print title_tr.shape\n",
    "print title_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data [optional]\n",
    "\n",
    "* The next tab can be used to stash all the essential data matrices and get rid of the rest of the data.\n",
    " * Highly recommended if you have less than 1.5GB RAM left\n",
    "* To do that, you need to first run it with save_prepared_data=True, then restart the notebook and only run this tab with read_prepared_data=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data (may take up to 3 minutes)\n",
      "готово\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = True #save\n",
    "read_prepared_data = False #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Saving preprocessed data (may take up to 3 minutes)\"\n",
    "    data_tuple = (title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts)\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Reading saved data...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print \"done\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the monster\n",
    "\n",
    "Since we have several data sources, our neural network may differ from what you used to work with.\n",
    "\n",
    "* Separate input for titles: RNN\n",
    "* Separate input for description: RNN\n",
    "* Separate input for categorical features: обычные полносвязные слои или какие-нибудь трюки\n",
    " \n",
    "These three inputs must be blended somehow - concatenated or added.\n",
    "\n",
    "* Output: a simple binary classification\n",
    " * 1 sigmoidal with binary_crossentropy\n",
    " * 2 softmax with categorical_crossentropy - essentially the same as previous one\n",
    " * 1 neuron without nonlinearity (lambda x: x) +  hinge loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3 inputs and a refere output\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 67) 67\n",
      "(None, 15)\n"
     ]
    }
   ],
   "source": [
    "print cat_inp.shape, nontext_tr.shape[1]\n",
    "print title_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "\n",
    "#word-wise embedding. We recommend to start from some 64 and improving after you are certain it works.\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id) + 1, output_size=128)\n",
    "#descr_nn = RNN or LSTM over embedding, maybe several ones in a stack\n",
    "descr_nn = lasagne.layers.RecurrentLayer(descr_nn, num_units=1024, grad_clipping=5)\n",
    "\n",
    "# Titles\n",
    "#title_nn = <Process titles somehow (title_inp)>\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp, input_size=len(token_to_id) + 1, output_size=128)\n",
    "title_nn = lasagne.layers.RecurrentLayer(title_nn, num_units=1024, grad_clipping=5)\n",
    "\n",
    "# Non-sequences\n",
    "#l_in = InputLayer((nontext_tr.shape[1], 64))\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, 256, nonlinearity=lasagne.nonlinearities.elu) #<Process non-sequences(cat_inp)>\n",
    "cat_nn = lasagne.layers.DropoutLayer(cat_nn, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n",
      "(None, 150, 1024)\n",
      "(None, 15, 1024)\n"
     ]
    }
   ],
   "source": [
    "print cat_nn.output_shape\n",
    "print descr_nn.output_shape\n",
    "print title_nn.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "#nn = <merge three layers into one (e.g. lasagne.layers.concat) >                                  \n",
    "nn = lasagne.layers.ConcatLayer([descr_nn, title_nn]) \n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn, 1024)\n",
    "print nn.output_shape\n",
    "nn = lasagne.layers.ConcatLayer([nn, cat_nn]) \n",
    "nn = lasagne.layers.DropoutLayer(nn, p=0.5)\n",
    "nn = lasagne.layers.DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "* The standard way:\n",
    " * prediction\n",
    " * loss\n",
    " * updates\n",
    " * training and evaluation functions\n",
    " \n",
    " \n",
    "* Hinge loss\n",
    " * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    " * delta is a tunable parameter: how far should a neuron be in the positive margin area for us to stop bothering about it\n",
    " * Function description may mention some +-1  limitations - this is not neccessary, at least as long as hinge loss has a __default__ flag `binary = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#Hinge loss\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction, target_y, delta = 0.5).mean()\n",
    "#loss = binary_hinge_loss(prediction,target_y,delta = 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "Subtensor{::, int64}.0\n"
     ]
    }
   ],
   "source": [
    "print loss\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=1e-5) \n",
    "#.nesterov_momentum(loss, weights, learning_rate=1e-4, momentum=.9) #<your favorite optimizer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinitic prediction \n",
    " * In case we use stochastic elements, e.g. dropout or noize\n",
    " * Compile a separate set of functions with deterministic prediction (deterministic = True)\n",
    " * Unless you think there's no neet for dropout there ofc. Btw is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#deterministic version\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#equivalent loss function\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(det_prediction, target_y, delta=0.5).mean() #<an excercise in copy-pasting and editing>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.compile.nanguardmode import NanGuardMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coffee-lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates \\\n",
    "                            )#mode=NanGuardMode(nan_is_error=True, inf_is_error=True, big_is_error=True))\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "* The regular way with loops over minibatches\n",
    "* Since the dataset is huge, we define epoch as some fixed amount of samples isntead of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        #print len(arrays[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        #print(excerpt)\n",
    "        #print [arr[excerpt] for arr in arrays]\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking guide\n",
    "\n",
    "* batch_size - how many samples are processed per function call\n",
    "  * optimization gets slower, but more stable, as you increase it.\n",
    "  * May consider increasing it halfway through training\n",
    "* minibatches_per_epoch - max amount of minibatches per epoch\n",
    "  * Does not affect training. Lesser value means more frequent and less stable printing\n",
    "  * Setting it to less than 10 is only meaningfull if you want to make sure your NN does not break down after one epoch\n",
    "* n_epochs - total amount of epochs to train for\n",
    "  * `n_epochs = 10**10` and manual interrupting is still an option\n",
    "\n",
    "\n",
    "Tips:\n",
    "\n",
    "* With small minibatches_per_epoch, network quality may jump around 0.5 for several epochs\n",
    "\n",
    "* AUC is the most stable of all three metrics\n",
    "\n",
    "* Average Precision at top 2.5% (APatK) - is the least stable. If batch_size*minibatches_per_epoch < 10k, it behaves as a uniform random variable.\n",
    "\n",
    "* Plotting metrics over training time may be a good way to analyze which architectures work better.\n",
    "\n",
    "* Once you are sure your network aint gonna crash, it's worth letting it train for a few hours of an average laptop's time to see it's true potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412494, 150) (412494, 15) (412494, 67) (412494,)\n"
     ]
    }
   ],
   "source": [
    "print desc_tr.shape, title_tr.shape, nontext_tr.shape, target_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train:\n",
      "\tloss: 0.320200016428\n",
      "\tacc: 0.844257425743\n",
      "\tauc: 0.926285528806\n",
      "\tap@k: 0.982746811668\n",
      "Val:\n",
      "\tloss: 0.317730065921\n",
      "\tacc: 0.858217821782\n",
      "\tauc: 0.933137774885\n",
      "\tap@k: 0.989869184007\n",
      "Epoch 2\n",
      "Train:\n",
      "\tloss: 0.311740781842\n",
      "\tacc: 0.842376237624\n",
      "\tauc: 0.924045390193\n",
      "\tap@k: 0.974612293314\n",
      "Val:\n",
      "\tloss: 0.324310258012\n",
      "\tacc: 0.885940594059\n",
      "\tauc: 0.938551860489\n",
      "\tap@k: 0.97106103515\n",
      "Epoch 3\n",
      "Train:\n",
      "\tloss: 0.3129317935\n",
      "\tacc: 0.84702970297\n",
      "\tauc: 0.926561125511\n",
      "\tap@k: 0.996765793905\n",
      "Val:\n",
      "\tloss: 0.311121840334\n",
      "\tacc: 0.861782178218\n",
      "\tauc: 0.938392450145\n",
      "\tap@k: 0.992500501554\n",
      "Epoch 4\n",
      "Train:\n",
      "\tloss: 0.308971024089\n",
      "\tacc: 0.859603960396\n",
      "\tauc: 0.936830408363\n",
      "\tap@k: 0.997333375059\n",
      "Val:\n",
      "\tloss: 0.301860559949\n",
      "\tacc: 0.847920792079\n",
      "\tauc: 0.945594138174\n",
      "\tap@k: 0.999321238242\n",
      "Epoch 5\n",
      "Train:\n",
      "\tloss: 0.309133572341\n",
      "\tacc: 0.859603960396\n",
      "\tauc: 0.938489614581\n",
      "\tap@k: 0.995421484039\n",
      "Val:\n",
      "\tloss: 0.307641905172\n",
      "\tacc: 0.857425742574\n",
      "\tauc: 0.940005542411\n",
      "\tap@k: 0.999466636235\n",
      "Epoch 6\n",
      "Train:\n",
      "\tloss: 0.313845325259\n",
      "\tacc: 0.863465346535\n",
      "\tauc: 0.935757775683\n",
      "\tap@k: 0.973856925921\n",
      "Val:\n",
      "\tloss: 0.30518163708\n",
      "\tacc: 0.885544554455\n",
      "\tauc: 0.944886452044\n",
      "\tap@k: 0.995803040989\n",
      "Epoch 7\n",
      "Train:\n",
      "\tloss: 0.302374803688\n",
      "\tacc: 0.875247524752\n",
      "\tauc: 0.945279987408\n",
      "\tap@k: 0.988422054885\n",
      "Val:\n",
      "\tloss: 0.310030344224\n",
      "\tacc: 0.852376237624\n",
      "\tauc: 0.94713451154\n",
      "\tap@k: 0.98255261725\n",
      "Epoch 8\n",
      "Train:\n",
      "\tloss: 0.302048941394\n",
      "\tacc: 0.883069306931\n",
      "\tauc: 0.944952643964\n",
      "\tap@k: 0.975839604204\n",
      "Val:\n",
      "\tloss: 0.305057522987\n",
      "\tacc: 0.895643564356\n",
      "\tauc: 0.949025932051\n",
      "\tap@k: 0.950002727041\n",
      "Epoch 9\n",
      "Train:\n",
      "\tloss: 0.302850000331\n",
      "\tacc: 0.878415841584\n",
      "\tauc: 0.948181711131\n",
      "\tap@k: 0.951791606911\n",
      "Val:\n",
      "\tloss: 0.299845330388\n",
      "\tacc: 0.883663366337\n",
      "\tauc: 0.951648451623\n",
      "\tap@k: 0.975403752155\n",
      "Epoch 10\n",
      "Train:\n",
      "\tloss: 0.300310974498\n",
      "\tacc: 0.887326732673\n",
      "\tauc: 0.953047260718\n",
      "\tap@k: 0.981343421072\n",
      "Val:\n",
      "\tloss: 0.297804929963\n",
      "\tacc: 0.90495049505\n",
      "\tauc: 0.949366764589\n",
      "\tap@k: 0.964964311759\n",
      "Epoch 11\n",
      "Train:\n",
      "\tloss: 0.294443939946\n",
      "\tacc: 0.884554455446\n",
      "\tauc: 0.950515548144\n",
      "\tap@k: 0.9900697898\n",
      "Val:\n",
      "\tloss: 0.294593550173\n",
      "\tacc: 0.910396039604\n",
      "\tauc: 0.959682765223\n",
      "\tap@k: 0.999412736822\n",
      "Epoch 12\n",
      "Train:\n",
      "\tloss: 0.29358253498\n",
      "\tacc: 0.891188118812\n",
      "\tauc: 0.956808034226\n",
      "\tap@k: 0.965637508324\n",
      "Val:\n",
      "\tloss: 0.294847664472\n",
      "\tacc: 0.903267326733\n",
      "\tauc: 0.959249361086\n",
      "\tap@k: 0.975271413875\n",
      "Epoch 13\n",
      "Train:\n",
      "\tloss: 0.287484944826\n",
      "\tacc: 0.904356435644\n",
      "\tauc: 0.961544951954\n",
      "\tap@k: 0.969780808176\n",
      "Val:\n",
      "\tloss: 0.299800927193\n",
      "\tacc: 0.921683168317\n",
      "\tauc: 0.95979354496\n",
      "\tap@k: 0.966297159193\n",
      "Epoch 14\n",
      "Train:\n",
      "\tloss: 0.291339305146\n",
      "\tacc: 0.90900990099\n",
      "\tauc: 0.964789914398\n",
      "\tap@k: 0.957850634907\n",
      "Val:\n",
      "\tloss: 0.295989732577\n",
      "\tacc: 0.913168316832\n",
      "\tauc: 0.958597528528\n",
      "\tap@k: 0.92230544311\n",
      "Epoch 15\n",
      "Train:\n",
      "\tloss: 0.290472918044\n",
      "\tacc: 0.897425742574\n",
      "\tauc: 0.959685992762\n",
      "\tap@k: 0.96394761444\n",
      "Val:\n",
      "\tloss: 0.294903826119\n",
      "\tacc: 0.921584158416\n",
      "\tauc: 0.963313647059\n",
      "\tap@k: 0.992402043909\n",
      "Epoch 16\n",
      "Train:\n",
      "\tloss: 0.290328039773\n",
      "\tacc: 0.901287128713\n",
      "\tauc: 0.964343946672\n",
      "\tap@k: 0.969399379125\n",
      "Val:\n",
      "\tloss: 0.291828168035\n",
      "\tacc: 0.921881188119\n",
      "\tauc: 0.969694358446\n",
      "\tap@k: 0.993685976063\n",
      "Epoch 17\n",
      "Train:\n",
      "\tloss: 0.288026506604\n",
      "\tacc: 0.912178217822\n",
      "\tauc: 0.969037506682\n",
      "\tap@k: 0.971779695856\n",
      "Val:\n",
      "\tloss: 0.292855232676\n",
      "\tacc: 0.923564356436\n",
      "\tauc: 0.967123128619\n",
      "\tap@k: 0.952251254372\n",
      "Epoch 18\n",
      "Train:\n",
      "\tloss: 0.288050764554\n",
      "\tacc: 0.907524752475\n",
      "\tauc: 0.965934134835\n",
      "\tap@k: 0.920362593969\n",
      "Val:\n",
      "\tloss: 0.287672956622\n",
      "\tacc: 0.928217821782\n",
      "\tauc: 0.971625192496\n",
      "\tap@k: 0.989868349968\n",
      "Epoch 19\n",
      "Train:\n",
      "\tloss: 0.282687194419\n",
      "\tacc: 0.914554455446\n",
      "\tauc: 0.969274975269\n",
      "\tap@k: 0.991431828549\n",
      "Val:\n",
      "\tloss: 0.288680720147\n",
      "\tacc: 0.913663366337\n",
      "\tauc: 0.971751305531\n",
      "\tap@k: 0.996544283391\n",
      "Epoch 20\n",
      "Train:\n",
      "\tloss: 0.284631284767\n",
      "\tacc: 0.919306930693\n",
      "\tauc: 0.971796106987\n",
      "\tap@k: 0.95288244663\n",
      "Val:\n",
      "\tloss: 0.287504741917\n",
      "\tacc: 0.919702970297\n",
      "\tauc: 0.969800857924\n",
      "\tap@k: 0.989968843826\n",
      "Epoch 21\n",
      "Train:\n",
      "\tloss: 0.280817233241\n",
      "\tacc: 0.921188118812\n",
      "\tauc: 0.971019468634\n",
      "\tap@k: 0.948302190062\n",
      "Val:\n",
      "\tloss: 0.285762404774\n",
      "\tacc: 0.917227722772\n",
      "\tauc: 0.974679382375\n",
      "\tap@k: 1.0\n",
      "Epoch 22\n",
      "Train:\n",
      "\tloss: 0.28305844503\n",
      "\tacc: 0.918613861386\n",
      "\tauc: 0.972357730399\n",
      "\tap@k: 0.976584850459\n",
      "Val:\n",
      "\tloss: 0.280298726322\n",
      "\tacc: 0.933762376238\n",
      "\tauc: 0.972346267578\n",
      "\tap@k: 0.981736965344\n",
      "Epoch 23\n",
      "Train:\n",
      "\tloss: 0.280254569435\n",
      "\tacc: 0.923564356436\n",
      "\tauc: 0.974153437025\n",
      "\tap@k: 0.988871107308\n",
      "Val:\n",
      "\tloss: 0.289859856585\n",
      "\tacc: 0.930792079208\n",
      "\tauc: 0.97179928932\n",
      "\tap@k: 0.992057251256\n",
      "Epoch 24\n",
      "Train:\n",
      "\tloss: 0.279125034502\n",
      "\tacc: 0.921485148515\n",
      "\tauc: 0.974690921788\n",
      "\tap@k: 0.985609421442\n",
      "Val:\n",
      "\tloss: 0.281112214877\n",
      "\tacc: 0.93900990099\n",
      "\tauc: 0.979422529286\n",
      "\tap@k: 1.0\n",
      "Epoch 25\n",
      "Train:\n",
      "\tloss: 0.277162927012\n",
      "\tacc: 0.927524752475\n",
      "\tauc: 0.977789877044\n",
      "\tap@k: 0.990322000689\n",
      "Val:\n",
      "\tloss: 0.281566528594\n",
      "\tacc: 0.928415841584\n",
      "\tauc: 0.976452568006\n",
      "\tap@k: 0.99939460577\n",
      "Epoch 26\n",
      "Train:\n",
      "\tloss: 0.282098155189\n",
      "\tacc: 0.928910891089\n",
      "\tauc: 0.978049747422\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.280401861789\n",
      "\tacc: 0.92900990099\n",
      "\tauc: 0.977728558444\n",
      "\tap@k: 1.0\n",
      "Epoch 27\n",
      "Train:\n",
      "\tloss: 0.278990292986\n",
      "\tacc: 0.926237623762\n",
      "\tauc: 0.974565357777\n",
      "\tap@k: 0.993281688481\n",
      "Val:\n",
      "\tloss: 0.285012411878\n",
      "\tacc: 0.922376237624\n",
      "\tauc: 0.978833477322\n",
      "\tap@k: 1.0\n",
      "Epoch 28\n",
      "Train:\n",
      "\tloss: 0.279936784412\n",
      "\tacc: 0.930495049505\n",
      "\tauc: 0.975933530279\n",
      "\tap@k: 0.987798980866\n",
      "Val:\n",
      "\tloss: 0.282617937724\n",
      "\tacc: 0.93900990099\n",
      "\tauc: 0.975477268806\n",
      "\tap@k: 1.0\n",
      "Epoch 29\n",
      "Train:\n",
      "\tloss: 0.277884430977\n",
      "\tacc: 0.920891089109\n",
      "\tauc: 0.972186846427\n",
      "\tap@k: 0.991690290153\n",
      "Val:\n",
      "\tloss: 0.285485971381\n",
      "\tacc: 0.913465346535\n",
      "\tauc: 0.976496578105\n",
      "\tap@k: 0.999589614771\n",
      "Epoch 30\n",
      "Train:\n",
      "\tloss: 0.281234703004\n",
      "\tacc: 0.91900990099\n",
      "\tauc: 0.977162048824\n",
      "\tap@k: 0.99459424909\n",
      "Val:\n",
      "\tloss: 0.286865729626\n",
      "\tacc: 0.897425742574\n",
      "\tauc: 0.977747036174\n",
      "\tap@k: 1.0\n",
      "Epoch 31\n",
      "Train:\n",
      "\tloss: 0.275438602399\n",
      "\tacc: 0.93297029703\n",
      "\tauc: 0.981564049297\n",
      "\tap@k: 0.997375538348\n",
      "Val:\n",
      "\tloss: 0.283484600433\n",
      "\tacc: 0.942772277228\n",
      "\tauc: 0.979614206712\n",
      "\tap@k: 0.996160011877\n",
      "Epoch 32\n",
      "Train:\n",
      "\tloss: 0.281036591367\n",
      "\tacc: 0.93099009901\n",
      "\tauc: 0.97791590906\n",
      "\tap@k: 0.99579557219\n",
      "Val:\n",
      "\tloss: 0.28218929437\n",
      "\tacc: 0.936435643564\n",
      "\tauc: 0.979114124901\n",
      "\tap@k: 0.998932467011\n",
      "Epoch 33\n",
      "Train:\n",
      "\tloss: 0.273680584746\n",
      "\tacc: 0.93801980198\n",
      "\tauc: 0.982130863311\n",
      "\tap@k: 0.994590161136\n",
      "Val:\n",
      "\tloss: 0.281182644412\n",
      "\tacc: 0.936633663366\n",
      "\tauc: 0.979281245843\n",
      "\tap@k: 1.0\n",
      "Epoch 34\n",
      "Train:\n",
      "\tloss: 0.27573555913\n",
      "\tacc: 0.935346534653\n",
      "\tauc: 0.980427469571\n",
      "\tap@k: 0.985882129361\n",
      "Val:\n",
      "\tloss: 0.282000029672\n",
      "\tacc: 0.933663366337\n",
      "\tauc: 0.978802171587\n",
      "\tap@k: 0.997965308177\n",
      "Epoch 35\n",
      "Train:\n",
      "\tloss: 0.272873488825\n",
      "\tacc: 0.936138613861\n",
      "\tauc: 0.978659326201\n",
      "\tap@k: 0.997750879791\n",
      "Val:\n",
      "\tloss: 0.275052289563\n",
      "\tacc: 0.93702970297\n",
      "\tauc: 0.979667446688\n",
      "\tap@k: 1.0\n",
      "Epoch 36\n",
      "Train:\n",
      "\tloss: 0.273337471374\n",
      "\tacc: 0.934158415842\n",
      "\tauc: 0.979052283879\n",
      "\tap@k: 0.99265582306\n",
      "Val:\n",
      "\tloss: 0.284180800787\n",
      "\tacc: 0.927920792079\n",
      "\tauc: 0.979648640778\n",
      "\tap@k: 1.0\n",
      "Epoch 37\n",
      "Train:\n",
      "\tloss: 0.274200864424\n",
      "\tacc: 0.933168316832\n",
      "\tauc: 0.979470890865\n",
      "\tap@k: 0.997050224132\n",
      "Val:\n",
      "\tloss: 0.283467538947\n",
      "\tacc: 0.936237623762\n",
      "\tauc: 0.978644379667\n",
      "\tap@k: 1.0\n",
      "Epoch 38\n",
      "Train:\n",
      "\tloss: 0.277961949787\n",
      "\tacc: 0.933861386139\n",
      "\tauc: 0.979088517339\n",
      "\tap@k: 0.997060427474\n",
      "Val:\n",
      "\tloss: 0.279158158136\n",
      "\tacc: 0.934356435644\n",
      "\tauc: 0.979582955249\n",
      "\tap@k: 1.0\n",
      "Epoch 39\n",
      "Train:\n",
      "\tloss: 0.290145410261\n",
      "\tacc: 0.905544554455\n",
      "\tauc: 0.963481182163\n",
      "\tap@k: 0.996975684441\n",
      "Val:\n",
      "\tloss: 0.297943254021\n",
      "\tacc: 0.933762376238\n",
      "\tauc: 0.97481360243\n",
      "\tap@k: 1.0\n",
      "Epoch 40\n",
      "Train:\n",
      "\tloss: 0.289588039721\n",
      "\tacc: 0.913663366337\n",
      "\tauc: 0.970823972056\n",
      "\tap@k: 0.973320264985\n",
      "Val:\n",
      "\tloss: 0.284668228027\n",
      "\tacc: 0.933762376238\n",
      "\tauc: 0.976757028845\n",
      "\tap@k: 1.0\n",
      "Epoch 41\n",
      "Train:\n",
      "\tloss: 0.270730684546\n",
      "\tacc: 0.930594059406\n",
      "\tauc: 0.980626558306\n",
      "\tap@k: 0.995628349816\n",
      "Val:\n",
      "\tloss: 0.280915900642\n",
      "\tacc: 0.94900990099\n",
      "\tauc: 0.982316893154\n",
      "\tap@k: 0.99774288475\n",
      "Epoch 42\n",
      "Train:\n",
      "\tloss: 0.277965595791\n",
      "\tacc: 0.934356435644\n",
      "\tauc: 0.980913848296\n",
      "\tap@k: 0.998137589078\n",
      "Val:\n",
      "\tloss: 0.279258125845\n",
      "\tacc: 0.943465346535\n",
      "\tauc: 0.98400311311\n",
      "\tap@k: 0.999775453248\n",
      "Epoch 43\n",
      "Train:\n",
      "\tloss: 0.277783920392\n",
      "\tacc: 0.939702970297\n",
      "\tauc: 0.983291124596\n",
      "\tap@k: 0.99545018646\n",
      "Val:\n",
      "\tloss: 0.280243204673\n",
      "\tacc: 0.947227722772\n",
      "\tauc: 0.982131358257\n",
      "\tap@k: 0.998266601097\n",
      "Epoch 44\n",
      "Train:\n",
      "\tloss: 0.275325062045\n",
      "\tacc: 0.940297029703\n",
      "\tauc: 0.982540975224\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275340818024\n",
      "\tacc: 0.950495049505\n",
      "\tauc: 0.984673489734\n",
      "\tap@k: 1.0\n",
      "Epoch 45\n",
      "Train:\n",
      "\tloss: 0.268412792288\n",
      "\tacc: 0.944455445545\n",
      "\tauc: 0.984010985994\n",
      "\tap@k: 0.993634551033\n",
      "Val:\n",
      "\tloss: 0.277198511666\n",
      "\tacc: 0.948514851485\n",
      "\tauc: 0.983443846632\n",
      "\tap@k: 1.0\n",
      "Epoch 46\n",
      "Train:\n",
      "\tloss: 0.275111246816\n",
      "\tacc: 0.945742574257\n",
      "\tauc: 0.981931840713\n",
      "\tap@k: 0.991120041982\n",
      "Val:\n",
      "\tloss: 0.276560283054\n",
      "\tacc: 0.935742574257\n",
      "\tauc: 0.983172663676\n",
      "\tap@k: 1.0\n",
      "Epoch 47\n",
      "Train:\n",
      "\tloss: 0.275726842348\n",
      "\tacc: 0.938712871287\n",
      "\tauc: 0.981483703495\n",
      "\tap@k: 0.999170286756\n",
      "Val:\n",
      "\tloss: 0.27508138203\n",
      "\tacc: 0.935742574257\n",
      "\tauc: 0.982894874242\n",
      "\tap@k: 1.0\n",
      "Epoch 48\n",
      "Train:\n",
      "\tloss: 0.271751324389\n",
      "\tacc: 0.941881188119\n",
      "\tauc: 0.981823993247\n",
      "\tap@k: 0.997283614452\n",
      "Val:\n",
      "\tloss: 0.277144130842\n",
      "\tacc: 0.930198019802\n",
      "\tauc: 0.980836627761\n",
      "\tap@k: 1.0\n",
      "Epoch 49\n",
      "Train:\n",
      "\tloss: 0.274912963787\n",
      "\tacc: 0.937326732673\n",
      "\tauc: 0.982727629953\n",
      "\tap@k: 0.998740620701\n",
      "Val:\n",
      "\tloss: 0.279420020046\n",
      "\tacc: 0.92801980198\n",
      "\tauc: 0.981930553255\n",
      "\tap@k: 1.0\n",
      "Epoch 50\n",
      "Train:\n",
      "\tloss: 0.276260197708\n",
      "\tacc: 0.943267326733\n",
      "\tauc: 0.983390807474\n",
      "\tap@k: 0.988067510448\n",
      "Val:\n",
      "\tloss: 0.27983349891\n",
      "\tacc: 0.950396039604\n",
      "\tauc: 0.984056752647\n",
      "\tap@k: 1.0\n",
      "Epoch 51\n",
      "Train:\n",
      "\tloss: 0.272543683925\n",
      "\tacc: 0.940693069307\n",
      "\tauc: 0.981372715912\n",
      "\tap@k: 0.989191215512\n",
      "Val:\n",
      "\tloss: 0.277094453099\n",
      "\tacc: 0.931287128713\n",
      "\tauc: 0.983385151986\n",
      "\tap@k: 0.996534981126\n",
      "Epoch 52\n",
      "Train:\n",
      "\tloss: 0.275952716263\n",
      "\tacc: 0.939900990099\n",
      "\tauc: 0.982647266534\n",
      "\tap@k: 0.998217953631\n",
      "Val:\n",
      "\tloss: 0.279283252187\n",
      "\tacc: 0.940792079208\n",
      "\tauc: 0.982356430822\n",
      "\tap@k: 1.0\n",
      "Epoch 53\n",
      "Train:\n",
      "\tloss: 0.276516316067\n",
      "\tacc: 0.947128712871\n",
      "\tauc: 0.985104765417\n",
      "\tap@k: 0.990059919055\n",
      "Val:\n",
      "\tloss: 0.27491988255\n",
      "\tacc: 0.937326732673\n",
      "\tauc: 0.981620155662\n",
      "\tap@k: 0.999092592633\n",
      "Epoch 54\n",
      "Train:\n",
      "\tloss: 0.271924643915\n",
      "\tacc: 0.945148514851\n",
      "\tauc: 0.98402878934\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.274388677555\n",
      "\tacc: 0.947821782178\n",
      "\tauc: 0.982990121827\n",
      "\tap@k: 1.0\n",
      "Epoch 55\n",
      "Train:\n",
      "\tloss: 0.272369872489\n",
      "\tacc: 0.939603960396\n",
      "\tauc: 0.981572931485\n",
      "\tap@k: 0.985452571356\n",
      "Val:\n",
      "\tloss: 0.278352815848\n",
      "\tacc: 0.94702970297\n",
      "\tauc: 0.983273668772\n",
      "\tap@k: 0.977570501562\n",
      "Epoch 56\n",
      "Train:\n",
      "\tloss: 0.273150230319\n",
      "\tacc: 0.942475247525\n",
      "\tauc: 0.980846634421\n",
      "\tap@k: 0.980034692907\n",
      "Val:\n",
      "\tloss: 0.276679179523\n",
      "\tacc: 0.950198019802\n",
      "\tauc: 0.980138423425\n",
      "\tap@k: 1.0\n",
      "Epoch 57\n",
      "Train:\n",
      "\tloss: 0.269855345151\n",
      "\tacc: 0.948118811881\n",
      "\tauc: 0.984373183357\n",
      "\tap@k: 0.999519810524\n",
      "Val:\n",
      "\tloss: 0.277871094293\n",
      "\tacc: 0.945346534653\n",
      "\tauc: 0.982806201747\n",
      "\tap@k: 0.999658207606\n",
      "Epoch 58\n",
      "Train:\n",
      "\tloss: 0.271534616171\n",
      "\tacc: 0.948910891089\n",
      "\tauc: 0.98737091733\n",
      "\tap@k: 0.988951757915\n",
      "Val:\n",
      "\tloss: 0.271055475762\n",
      "\tacc: 0.949702970297\n",
      "\tauc: 0.982187382342\n",
      "\tap@k: 1.0\n",
      "Epoch 59\n",
      "Train:\n",
      "\tloss: 0.270309396914\n",
      "\tacc: 0.95099009901\n",
      "\tauc: 0.984557871344\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275243807908\n",
      "\tacc: 0.95504950495\n",
      "\tauc: 0.985335560511\n",
      "\tap@k: 0.999208568522\n",
      "Epoch 60\n",
      "Train:\n",
      "\tloss: 0.269822841798\n",
      "\tacc: 0.946336633663\n",
      "\tauc: 0.982526207503\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.279555443401\n",
      "\tacc: 0.943168316832\n",
      "\tauc: 0.979213335603\n",
      "\tap@k: 1.0\n",
      "Epoch 61\n",
      "Train:\n",
      "\tloss: 0.270053886591\n",
      "\tacc: 0.945940594059\n",
      "\tauc: 0.983259873061\n",
      "\tap@k: 0.996485004073\n",
      "Val:\n",
      "\tloss: 0.276077124626\n",
      "\tacc: 0.936633663366\n",
      "\tauc: 0.983612457227\n",
      "\tap@k: 0.998523959046\n",
      "Epoch 62\n",
      "Train:\n",
      "\tloss: 0.271026533088\n",
      "\tacc: 0.945643564356\n",
      "\tauc: 0.985687083253\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.276587813641\n",
      "\tacc: 0.953267326733\n",
      "\tauc: 0.98420878035\n",
      "\tap@k: 1.0\n",
      "Epoch 63\n",
      "Train:\n",
      "\tloss: 0.275567174783\n",
      "\tacc: 0.949306930693\n",
      "\tauc: 0.982245706227\n",
      "\tap@k: 0.99152818087\n",
      "Val:\n",
      "\tloss: 0.278428698475\n",
      "\tacc: 0.948910891089\n",
      "\tauc: 0.980682073966\n",
      "\tap@k: 1.0\n",
      "Epoch 64\n",
      "Train:\n",
      "\tloss: 0.271267641489\n",
      "\tacc: 0.948514851485\n",
      "\tauc: 0.984355322301\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275986260343\n",
      "\tacc: 0.947524752475\n",
      "\tauc: 0.985595799634\n",
      "\tap@k: 1.0\n",
      "Epoch 65\n",
      "Train:\n",
      "\tloss: 0.268398903943\n",
      "\tacc: 0.947524752475\n",
      "\tauc: 0.983278996897\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.273700371743\n",
      "\tacc: 0.942277227723\n",
      "\tauc: 0.982043810504\n",
      "\tap@k: 1.0\n",
      "Epoch 66\n",
      "Train:\n",
      "\tloss: 0.265858449841\n",
      "\tacc: 0.954554455446\n",
      "\tauc: 0.985774486601\n",
      "\tap@k: 0.999112159807\n",
      "Val:\n",
      "\tloss: 0.273774436009\n",
      "\tacc: 0.945544554455\n",
      "\tauc: 0.983528271207\n",
      "\tap@k: 1.0\n",
      "Epoch 67\n",
      "Train:\n",
      "\tloss: 0.268162362917\n",
      "\tacc: 0.951683168317\n",
      "\tauc: 0.98500126111\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275284628142\n",
      "\tacc: 0.939306930693\n",
      "\tauc: 0.982807527367\n",
      "\tap@k: 0.999502165126\n",
      "Epoch 68\n",
      "Train:\n",
      "\tloss: 0.271179534878\n",
      "\tacc: 0.953168316832\n",
      "\tauc: 0.986736414289\n",
      "\tap@k: 0.997005752629\n",
      "Val:\n",
      "\tloss: 0.277890986669\n",
      "\tacc: 0.947425742574\n",
      "\tauc: 0.979545367117\n",
      "\tap@k: 1.0\n",
      "Epoch 69\n",
      "Train:\n",
      "\tloss: 0.273714904848\n",
      "\tacc: 0.944752475248\n",
      "\tauc: 0.983068858011\n",
      "\tap@k: 0.989202169395\n",
      "Val:\n",
      "\tloss: 0.277885902968\n",
      "\tacc: 0.942772277228\n",
      "\tauc: 0.986364381807\n",
      "\tap@k: 1.0\n",
      "Epoch 70\n",
      "Train:\n",
      "\tloss: 0.271524141453\n",
      "\tacc: 0.94495049505\n",
      "\tauc: 0.984283421125\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.277820482816\n",
      "\tacc: 0.935346534653\n",
      "\tauc: 0.986033504766\n",
      "\tap@k: 0.996303546962\n",
      "Epoch 71\n",
      "Train:\n",
      "\tloss: 0.269050158711\n",
      "\tacc: 0.950495049505\n",
      "\tauc: 0.985863951191\n",
      "\tap@k: 0.997703883754\n",
      "Val:\n",
      "\tloss: 0.272250666305\n",
      "\tacc: 0.941386138614\n",
      "\tauc: 0.984540627173\n",
      "\tap@k: 1.0\n",
      "Epoch 72\n",
      "Train:\n",
      "\tloss: 0.26947559473\n",
      "\tacc: 0.948811881188\n",
      "\tauc: 0.98521138729\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.274268470942\n",
      "\tacc: 0.937920792079\n",
      "\tauc: 0.984427295753\n",
      "\tap@k: 1.0\n",
      "Epoch 73\n",
      "Train:\n",
      "\tloss: 0.274790493969\n",
      "\tacc: 0.951584158416\n",
      "\tauc: 0.98647309681\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.27537685402\n",
      "\tacc: 0.945346534653\n",
      "\tauc: 0.986065012167\n",
      "\tap@k: 1.0\n",
      "Epoch 74\n",
      "Train:\n",
      "\tloss: 0.270042892146\n",
      "\tacc: 0.952079207921\n",
      "\tauc: 0.987886056442\n",
      "\tap@k: 0.998613539279\n",
      "Val:\n",
      "\tloss: 0.272678018942\n",
      "\tacc: 0.95396039604\n",
      "\tauc: 0.985195346071\n",
      "\tap@k: 0.999227571258\n",
      "Epoch 75\n",
      "Train:\n",
      "\tloss: 0.268505445168\n",
      "\tacc: 0.951881188119\n",
      "\tauc: 0.98751232189\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275723508351\n",
      "\tacc: 0.953663366337\n",
      "\tauc: 0.98479803513\n",
      "\tap@k: 1.0\n",
      "Epoch 76\n",
      "Train:\n",
      "\tloss: 0.267493563646\n",
      "\tacc: 0.956831683168\n",
      "\tauc: 0.986846683341\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.275189618735\n",
      "\tacc: 0.952772277228\n",
      "\tauc: 0.986777732918\n",
      "\tap@k: 1.0\n",
      "Epoch 77\n",
      "Train:\n",
      "\tloss: 0.267372799157\n",
      "\tacc: 0.951881188119\n",
      "\tauc: 0.986497871317\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.270151401325\n",
      "\tacc: 0.954059405941\n",
      "\tauc: 0.984495041174\n",
      "\tap@k: 1.0\n",
      "Epoch 78\n",
      "Train:\n",
      "\tloss: 0.272502054432\n",
      "\tacc: 0.949603960396\n",
      "\tauc: 0.98366740207\n",
      "\tap@k: 0.984455865682\n",
      "Val:\n",
      "\tloss: 0.281043221084\n",
      "\tacc: 0.918415841584\n",
      "\tauc: 0.97730697616\n",
      "\tap@k: 1.0\n",
      "Epoch 79\n",
      "Train:\n",
      "\tloss: 0.27222454109\n",
      "\tacc: 0.945247524752\n",
      "\tauc: 0.981097794334\n",
      "\tap@k: 0.993102147133\n",
      "Val:\n",
      "\tloss: 0.286817672744\n",
      "\tacc: 0.899801980198\n",
      "\tauc: 0.975900455302\n",
      "\tap@k: 0.999589614771\n",
      "Epoch 80\n",
      "Train:\n",
      "\tloss: 0.275728841684\n",
      "\tacc: 0.945247524752\n",
      "\tauc: 0.984872517818\n",
      "\tap@k: 0.989629907204\n",
      "Val:\n",
      "\tloss: 0.277796018206\n",
      "\tacc: 0.940297029703\n",
      "\tauc: 0.982967852868\n",
      "\tap@k: 1.0\n",
      "Epoch 81\n",
      "Train:\n",
      "\tloss: 0.269493681823\n",
      "\tacc: 0.951584158416\n",
      "\tauc: 0.986801311527\n",
      "\tap@k: 0.99915100593\n",
      "Val:\n",
      "\tloss: 0.27592338443\n",
      "\tacc: 0.946930693069\n",
      "\tauc: 0.983285049148\n",
      "\tap@k: 0.99609976296\n",
      "Epoch 82\n",
      "Train:\n",
      "\tloss: 0.272628856962\n",
      "\tacc: 0.952178217822\n",
      "\tauc: 0.986293516362\n",
      "\tap@k: 0.984710668652\n",
      "Val:\n",
      "\tloss: 0.277434874012\n",
      "\tacc: 0.946336633663\n",
      "\tauc: 0.983716399826\n",
      "\tap@k: 0.987093015912\n",
      "Epoch 83\n",
      "Train:\n",
      "\tloss: 0.272001507962\n",
      "\tacc: 0.945940594059\n",
      "\tauc: 0.979590249403\n",
      "\tap@k: 0.980268951549\n",
      "Val:\n",
      "\tloss: 0.27363825392\n",
      "\tacc: 0.947623762376\n",
      "\tauc: 0.982478952714\n",
      "\tap@k: 1.0\n",
      "Epoch 84\n",
      "Train:\n",
      "\tloss: 0.269325109785\n",
      "\tacc: 0.954158415842\n",
      "\tauc: 0.985668265316\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.273570462476\n",
      "\tacc: 0.956336633663\n",
      "\tauc: 0.984646856706\n",
      "\tap@k: 1.0\n",
      "Epoch 85\n",
      "Train:\n",
      "\tloss: 0.272802853958\n",
      "\tacc: 0.952673267327\n",
      "\tauc: 0.98468687756\n",
      "\tap@k: 0.996320978699\n",
      "Val:\n",
      "\tloss: 0.273383424283\n",
      "\tacc: 0.951881188119\n",
      "\tauc: 0.983900455976\n",
      "\tap@k: 1.0\n",
      "Epoch 86\n",
      "Train:\n",
      "\tloss: 0.266262448686\n",
      "\tacc: 0.953861386139\n",
      "\tauc: 0.984939537337\n",
      "\tap@k: 0.992950654997\n",
      "Val:\n",
      "\tloss: 0.266474643902\n",
      "\tacc: 0.954752475248\n",
      "\tauc: 0.98248548342\n",
      "\tap@k: 1.0\n",
      "Epoch 87\n",
      "Train:\n",
      "\tloss: 0.269876880819\n",
      "\tacc: 0.954455445545\n",
      "\tauc: 0.984300222466\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.269369366012\n",
      "\tacc: 0.953168316832\n",
      "\tauc: 0.982691686179\n",
      "\tap@k: 0.997283614452\n",
      "Epoch 88\n",
      "Train:\n",
      "\tloss: 0.268484585343\n",
      "\tacc: 0.954653465347\n",
      "\tauc: 0.984000154338\n",
      "\tap@k: 0.997922832115\n",
      "Val:\n",
      "\tloss: 0.2719718452\n",
      "\tacc: 0.95702970297\n",
      "\tauc: 0.986072522247\n",
      "\tap@k: 1.0\n",
      "Epoch 89\n",
      "Train:\n",
      "\tloss: 0.271265485976\n",
      "\tacc: 0.953366336634\n",
      "\tauc: 0.984920780623\n",
      "\tap@k: 0.995549551661\n",
      "Val:\n",
      "\tloss: 0.273270124524\n",
      "\tacc: 0.955940594059\n",
      "\tauc: 0.983958944572\n",
      "\tap@k: 0.998569002935\n",
      "Epoch 90\n",
      "Train:\n",
      "\tloss: 0.2670315481\n",
      "\tacc: 0.958910891089\n",
      "\tauc: 0.985244017473\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.272617966489\n",
      "\tacc: 0.951386138614\n",
      "\tauc: 0.984582826707\n",
      "\tap@k: 1.0\n",
      "Epoch 91\n",
      "Train:\n",
      "\tloss: 0.268556497952\n",
      "\tacc: 0.950495049505\n",
      "\tauc: 0.985936549784\n",
      "\tap@k: 0.995931688682\n",
      "Val:\n",
      "\tloss: 0.273956088358\n",
      "\tacc: 0.955742574257\n",
      "\tauc: 0.984794507608\n",
      "\tap@k: 0.997298871095\n",
      "Epoch 92\n",
      "Train:\n",
      "\tloss: 0.268886977284\n",
      "\tacc: 0.954554455446\n",
      "\tauc: 0.987057830532\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.271272839482\n",
      "\tacc: 0.958118811881\n",
      "\tauc: 0.986331125943\n",
      "\tap@k: 1.0\n",
      "Epoch 93\n",
      "Train:\n",
      "\tloss: 0.26759507538\n",
      "\tacc: 0.956534653465\n",
      "\tauc: 0.987822000258\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.270965592899\n",
      "\tacc: 0.957722772277\n",
      "\tauc: 0.98667591624\n",
      "\tap@k: 1.0\n",
      "Epoch 94\n",
      "Train:\n",
      "\tloss: 0.268641679991\n",
      "\tacc: 0.95603960396\n",
      "\tauc: 0.985609461616\n",
      "\tap@k: 0.995410759404\n",
      "Val:\n",
      "\tloss: 0.274885084696\n",
      "\tacc: 0.943267326733\n",
      "\tauc: 0.983038708973\n",
      "\tap@k: 0.999824655919\n",
      "Epoch 95\n",
      "Train:\n",
      "\tloss: 0.266130567109\n",
      "\tacc: 0.953861386139\n",
      "\tauc: 0.984523243775\n",
      "\tap@k: 0.991498314867\n",
      "Val:\n",
      "\tloss: 0.26925656315\n",
      "\tacc: 0.95396039604\n",
      "\tauc: 0.985040425431\n",
      "\tap@k: 0.999791922287\n",
      "Epoch 96\n",
      "Train:\n",
      "\tloss: 0.268239390789\n",
      "\tacc: 0.952475247525\n",
      "\tauc: 0.983140648684\n",
      "\tap@k: 0.976718715866\n",
      "Val:\n",
      "\tloss: 0.278707468242\n",
      "\tacc: 0.952772277228\n",
      "\tauc: 0.984329859316\n",
      "\tap@k: 1.0\n",
      "Epoch 97\n",
      "Train:\n",
      "\tloss: 0.269622143704\n",
      "\tacc: 0.958217821782\n",
      "\tauc: 0.986569468724\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.272631042233\n",
      "\tacc: 0.955643564356\n",
      "\tauc: 0.983933675532\n",
      "\tap@k: 1.0\n",
      "Epoch 98\n",
      "Train:\n",
      "\tloss: 0.264286422273\n",
      "\tacc: 0.952673267327\n",
      "\tauc: 0.98707111327\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.274050016187\n",
      "\tacc: 0.947524752475\n",
      "\tauc: 0.983373470581\n",
      "\tap@k: 0.997435654337\n",
      "Epoch 99\n",
      "Train:\n",
      "\tloss: 0.267780856783\n",
      "\tacc: 0.951881188119\n",
      "\tauc: 0.984460126555\n",
      "\tap@k: 0.99169314745\n",
      "Val:\n",
      "\tloss: 0.26707556198\n",
      "\tacc: 0.952079207921\n",
      "\tauc: 0.985836115078\n",
      "\tap@k: 1.0\n",
      "Epoch 100\n",
      "Train:\n",
      "\tloss: 0.268614594076\n",
      "\tacc: 0.951683168317\n",
      "\tauc: 0.984709494512\n",
      "\tap@k: 0.98040226017\n",
      "Val:\n",
      "\tloss: 0.269047941064\n",
      "\tacc: 0.948217821782\n",
      "\tauc: 0.984120897169\n",
      "\tap@k: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        #print loss\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Epoch\", i + 1 \n",
    "    #print epoch_y_true\n",
    "    #print epoch_y_pred\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.5)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.5)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Evaluate network over the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "\tloss: 0.273436105943\n",
      "\tacc: 0.946106259098\n",
      "\tauc: 0.981633825691\n",
      "\tap@k: 0.995200254882\n",
      "\n",
      "AUC:\n",
      "\tОтличное решение! (good)\n",
      "\n",
      "Accuracy:\n",
      "\tВсё ок (ok)\n",
      "\n",
      "Average precision at K:\n",
      "\tЗасабмить на kaggle! (great) \n",
      "\t Нет, ну честно - выкачай avito_test.tsv, засабмить и скажи, что вышло.\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0.5)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main task\n",
    "\n",
    "* https://goo.gl/forms/eJwIeAbjxzVuo6vn1\n",
    "* Feel like Le'Cun:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (test sample size * 0.025) > 0.99\n",
    " * And perhaps even farther\n",
    "\n",
    "* Casual mode\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (test sample size * 0.025) > 0.92\n",
    "\n",
    "* Remember the training, Luke\n",
    " * Dropout, regularization\n",
    " * Mommentum, RMSprop, ada*\n",
    " * etc etc etc\n",
    " \n",
    " * If you have background in texts, there may be a way to improve tokenizer, add some lemmatization, etc etc.\n",
    " * In case you know how not to shoot yourself in the foot with RNNs, they too may be of some use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
